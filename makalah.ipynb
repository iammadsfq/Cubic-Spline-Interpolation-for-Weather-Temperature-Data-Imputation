{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "2023-01-01    21.4\n",
      "2023-01-02    22.4\n",
      "2023-01-03    21.8\n",
      "2023-01-04    21.8\n",
      "2023-01-05    22.2\n",
      "              ... \n",
      "2023-12-27    22.6\n",
      "2023-12-28    23.5\n",
      "2023-12-29    23.4\n",
      "2023-12-30    22.3\n",
      "2023-12-31    22.3\n",
      "Freq: D, Name: tavg, Length: 365, dtype: float64\n",
      "time\n",
      "2023-01-01 00:00:00    19.9\n",
      "2023-01-01 01:00:00    20.9\n",
      "2023-01-01 02:00:00    21.7\n",
      "2023-01-01 03:00:00    23.6\n",
      "2023-01-01 04:00:00    23.2\n",
      "                       ... \n",
      "2023-12-31 19:00:00    21.3\n",
      "2023-12-31 20:00:00    19.6\n",
      "2023-12-31 21:00:00    20.8\n",
      "2023-12-31 22:00:00    20.4\n",
      "2023-12-31 23:00:00    19.2\n",
      "Freq: h, Name: temp, Length: 8760, dtype: float64\n",
      "\n",
      "Missing data:\n",
      "Daily: 0\n",
      "Hourly: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from meteostat import Point, Daily, Hourly\n",
    "from scipy.interpolate import CubicSpline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "location = Point(-6.9389, 107.7528)\n",
    "start = datetime(2023, 1, 1, 0, 0, 0)\n",
    "short_term_end = datetime(2023, 1, 7, 23, 59, 59) # 7 days\n",
    "medium_term_end = datetime(2023, 3, 31, 23, 59, 59) # 3 months\n",
    "long_term_end = datetime(2023, 12, 31, 23, 59, 59) # 1 year\n",
    "\n",
    "daily_long_data = Daily(location, start, long_term_end)\n",
    "daily_long_data = daily_long_data.fetch()\n",
    "\n",
    "hourly_long_data = Hourly(location, start, long_term_end)\n",
    "hourly_long_data = hourly_long_data.fetch()\n",
    "\n",
    "daily_long_temp = daily_long_data['tavg']\n",
    "daily_medium_temp = daily_long_temp[start:medium_term_end]\n",
    "hourly_long_temp = hourly_long_data['temp']\n",
    "hourly_medium_temp = hourly_long_temp[start:medium_term_end]\n",
    "hourly_short_temp = hourly_long_temp[start:short_term_end]\n",
    "print(daily_long_temp)\n",
    "print(hourly_long_temp)\n",
    "print(\"\\nMissing data:\")\n",
    "print(\"Daily:\", daily_long_temp.isnull().sum())\n",
    "print(\"Hourly:\", hourly_long_temp.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_missingness(data, rate, pattern=\"scattered\", block_size=12):\n",
    "    data_with_nan = data.copy()\n",
    "    n = len(data)\n",
    "    missing_indices = []\n",
    "    if pattern == \"scattered\":\n",
    "        missing_indices = np.random.choice(n, int(rate * n), replace=False)\n",
    "    elif pattern == \"block\":\n",
    "        num_blocks = int(rate * n / block_size)\n",
    "        for _ in range(num_blocks):\n",
    "            start_idx = np.random.randint(0, n - block_size)\n",
    "            missing_indices.extend(range(start_idx, start_idx + block_size))\n",
    "    data_with_nan.iloc[missing_indices] = np.nan\n",
    "    return data_with_nan\n",
    "\n",
    "missing_rates = [0.1, 0.2, 0.3]\n",
    "patterns = [\"scattered\", \"block\"]\n",
    "\n",
    "def create_missing_datasets(data, patterns, rates, block_size):\n",
    "    datasets = {}\n",
    "    for pattern in patterns:\n",
    "        for rate in rates:\n",
    "            key = f\"{pattern}_{int(rate*100)}\"\n",
    "            datasets[key] = introduce_missingness(data, rate, pattern, block_size)\n",
    "    return datasets\n",
    "\n",
    "hourly_missing_data_long = create_missing_datasets(hourly_long_temp, patterns, missing_rates, block_size=12)\n",
    "daily_missing_data_long = create_missing_datasets(daily_long_temp, patterns, missing_rates, block_size=7)\n",
    "hourly_missing_data_medium = create_missing_datasets(hourly_medium_temp, patterns, missing_rates, block_size=12)\n",
    "daily_missing_data_medium = create_missing_datasets(daily_medium_temp, patterns, missing_rates, block_size=7)\n",
    "hourly_missing_data_short = create_missing_datasets(hourly_short_temp, patterns, missing_rates, block_size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing data:\n",
      "Long-Hourly:\n",
      "  original: 8760\n",
      "  scattered_10: 876 missing values\n",
      "  scattered_20: 1752 missing values\n",
      "  scattered_30: 2628 missing values\n",
      "  block_10: 845 missing values\n",
      "  block_20: 1599 missing values\n",
      "  block_30: 2307 missing values\n",
      "Long-Daily:\n",
      "  original: 365\n",
      "  scattered_10: 36 missing values\n",
      "  scattered_20: 73 missing values\n",
      "  scattered_30: 109 missing values\n",
      "  block_10: 35 missing values\n",
      "  block_20: 61 missing values\n",
      "  block_30: 86 missing values\n",
      "Medium-Hourly:\n",
      "  original: 2160\n",
      "  scattered_10: 216 missing values\n",
      "  scattered_20: 432 missing values\n",
      "  scattered_30: 648 missing values\n",
      "  block_10: 203 missing values\n",
      "  block_20: 381 missing values\n",
      "  block_30: 562 missing values\n",
      "Medium-Daily:\n",
      "  original: 90\n",
      "  scattered_10: 9 missing values\n",
      "  scattered_20: 18 missing values\n",
      "  scattered_30: 27 missing values\n",
      "  block_10: 7 missing values\n",
      "  block_20: 14 missing values\n",
      "  block_30: 15 missing values\n",
      "Short-Hourly:\n",
      "  original: 168\n",
      "  scattered_10: 16 missing values\n",
      "  scattered_20: 33 missing values\n",
      "  scattered_30: 50 missing values\n",
      "  block_10: 12 missing values\n",
      "  block_20: 24 missing values\n",
      "  block_30: 36 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing data:\")\n",
    "\n",
    "print(\"Long-Hourly:\")\n",
    "print(f\"  original: {hourly_long_temp.notnull().sum()}\")\n",
    "for key, dataset in hourly_missing_data_long.items():\n",
    "    print(f\"  {key}: {dataset.isnull().sum().sum()} missing values\")\n",
    "\n",
    "print(\"Long-Daily:\")\n",
    "print(f\"  original: {daily_long_temp.notnull().sum()}\")\n",
    "for key, dataset in daily_missing_data_long.items():\n",
    "    print(f\"  {key}: {dataset.isnull().sum().sum()} missing values\")\n",
    "\n",
    "print(\"Medium-Hourly:\")\n",
    "print(f\"  original: {hourly_medium_temp.notnull().sum()}\")\n",
    "for key, dataset in hourly_missing_data_medium.items():\n",
    "    print(f\"  {key}: {dataset.isnull().sum().sum()} missing values\")\n",
    "\n",
    "print(\"Medium-Daily:\")\n",
    "print(f\"  original: {daily_medium_temp.notnull().sum()}\")\n",
    "for key, dataset in daily_missing_data_medium.items():\n",
    "    print(f\"  {key}: {dataset.isnull().sum().sum()} missing values\")\n",
    "\n",
    "print(\"Short-Hourly:\")\n",
    "print(f\"  original: {hourly_short_temp.notnull().sum()}\")\n",
    "for key, dataset in hourly_missing_data_short.items():\n",
    "    print(f\"  {key}: {dataset.isnull().sum().sum()} missing values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_spline_interpolation(original_data, missing_data):\n",
    "    interpolated_data = missing_data.copy()\n",
    "    observed_indices = ~missing_data.isna()\n",
    "    observed_x = np.arange(len(original_data))[observed_indices]\n",
    "    observed_y = original_data[observed_indices]\n",
    "\n",
    "    spline = CubicSpline(observed_x, observed_y)\n",
    "    interpolated_data[~observed_indices] = spline(np.arange(len(original_data))[~observed_indices])\n",
    "\n",
    "    return interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type    Pattern Rate (%) Granularity      RMSE       MAE\n",
      "0   Hourly  scattered       10        long  1.927739  1.446166\n",
      "1   Hourly  scattered       20        long  2.158186  1.623185\n",
      "2   Hourly  scattered       30        long  2.606162  1.803609\n",
      "3   Hourly      block       10        long  6.730402  5.252770\n",
      "4   Hourly      block       20        long  8.126094  5.946614\n",
      "5   Hourly      block       30        long  9.055209  6.346494\n",
      "6    Daily  scattered       10        long  0.479914  0.397070\n",
      "7    Daily  scattered       20        long  0.529246  0.381967\n",
      "8    Daily  scattered       30        long  0.771659  0.566188\n",
      "9    Daily      block       10        long  0.679802  0.563758\n",
      "10   Daily      block       20        long  1.900691  1.543932\n",
      "11   Daily      block       30        long  0.965083  0.850583\n",
      "12  Hourly  scattered       10      medium  2.119266  1.656264\n",
      "13  Hourly  scattered       20      medium  2.255280  1.723923\n",
      "14  Hourly  scattered       30      medium  2.479978  1.859630\n",
      "15  Hourly      block       10      medium  6.741903  5.319278\n",
      "16  Hourly      block       20      medium  9.164045  6.892313\n",
      "17  Hourly      block       30      medium  6.416011  5.123868\n",
      "18   Daily  scattered       10      medium  0.663787  0.490391\n",
      "19   Daily  scattered       20      medium  0.367881  0.307397\n",
      "20   Daily  scattered       30      medium  0.740189  0.612538\n",
      "21   Daily      block       10      medium  0.460572  0.383953\n",
      "22   Daily      block       20      medium  1.192308  0.915439\n",
      "23   Daily      block       30      medium  1.069782  0.899323\n",
      "24  Hourly  scattered       10       short  1.320718  1.111440\n",
      "25  Hourly  scattered       20       short  2.101309  1.617144\n",
      "26  Hourly  scattered       30       short  2.777084  2.062001\n",
      "27  Hourly      block       10       short  4.639215  4.149764\n",
      "28  Hourly      block       20       short  5.507050  4.689940\n",
      "29  Hourly      block       30       short  4.976727  4.041676\n"
     ]
    }
   ],
   "source": [
    "def evaluate_interpolation(original_data, interpolated_data, missing_data):\n",
    "    true_values = original_data[missing_data.isna()]\n",
    "    imputed_values = interpolated_data[missing_data.isna()]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, imputed_values))\n",
    "    mae = mean_absolute_error(true_values, imputed_values)\n",
    "    return rmse, mae\n",
    "results = []\n",
    "for dataset_type, datasets, original_data in zip(\n",
    "    [\"Hourly\", \"Daily\", \"Hourly\", \"Daily\", \"Hourly\"],\n",
    "    [\n",
    "        hourly_missing_data_long, daily_missing_data_long,\n",
    "        hourly_missing_data_medium, daily_missing_data_medium,\n",
    "        hourly_missing_data_short\n",
    "    ],\n",
    "    [\n",
    "        hourly_long_temp, daily_long_temp,\n",
    "        hourly_medium_temp, daily_medium_temp,\n",
    "        hourly_short_temp\n",
    "    ]\n",
    "):\n",
    "    granularity = (\n",
    "        \"long\" if id(original_data) in [id(hourly_long_temp), id(daily_long_temp)] else\n",
    "        \"medium\" if id(original_data) in [id(hourly_medium_temp), id(daily_medium_temp)] else\n",
    "        \"short\"\n",
    "    )\n",
    "    for key, missing_data in datasets.items():\n",
    "        interpolated_data = cubic_spline_interpolation(original_data, missing_data)\n",
    "        rmse, mae = evaluate_interpolation(original_data, interpolated_data, missing_data)\n",
    "        results.append([dataset_type, key.split(\"_\")[0], key.split(\"_\")[1], granularity, rmse, mae])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Type\", \"Pattern\", \"Rate (%)\", \"Granularity\", \"RMSE\", \"MAE\"])\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
